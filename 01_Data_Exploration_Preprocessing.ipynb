{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - Part 1: Data Exploration & Preprocessing\n",
    "\n",
    "## Overview\n",
    "This notebook covers:\n",
    "1. Data Loading and Initial Exploration\n",
    "2. Data Quality Assessment\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Data Preprocessing\n",
    "5. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Note: Update the path to your dataset location\n",
    "df = pd.read_csv('data/customer_data.csv')\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initial Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column information\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Missing Percentage': missing_percent.values\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(\"Missing Values Found:\")\n",
    "    print(missing_df)\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Target Variable Analysis (Churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "churn_percentages = df['Churn'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Churn Distribution:\")\n",
    "print(churn_counts)\n",
    "print(\"\\nChurn Percentages:\")\n",
    "print(churn_percentages)\n",
    "\n",
    "# Visualize churn distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar chart\n",
    "churn_counts.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "axes[0].set_title('Churn Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Churn', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "churn_percentages.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('Churn Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nChurn Rate: {churn_percentages['Yes']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Exploratory Data Analysis (EDA)\n",
    "\n",
    "### 5.1 Categorical Features Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "categorical_cols = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', \n",
    "                   'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                   'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
    "                   'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "# Analyze churn rate by each categorical feature\n",
    "def analyze_categorical_churn(df, col):\n",
    "    churn_by_category = pd.crosstab(df[col], df['Churn'], normalize='index') * 100\n",
    "    churn_by_category.columns = ['No Churn %', 'Churn %']\n",
    "    return churn_by_category.sort_values('Churn %', ascending=False)\n",
    "\n",
    "# Analyze key categorical features\n",
    "key_categorical = ['Contract', 'PaymentMethod', 'InternetService', 'OnlineSecurity']\n",
    "\n",
    "for col in key_categorical:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Churn Analysis for: {col}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    result = analyze_categorical_churn(df, col)\n",
    "    print(result)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    result['Churn %'].plot(kind='barh', color='#e74c3c')\n",
    "    plt.title(f'Churn Rate by {col}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Churn Percentage (%)', fontsize=12)\n",
    "    plt.ylabel(col, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Numerical Features Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "numerical_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "# Check TotalCharges data type (might be object if it has spaces)\n",
    "print(f\"TotalCharges data type: {df['TotalCharges'].dtype}\")\n",
    "print(f\"\\nSample TotalCharges values:\")\n",
    "print(df['TotalCharges'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to numeric (handling any non-numeric values)\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Check for missing values after conversion\n",
    "print(f\"Missing values in TotalCharges: {df['TotalCharges'].isnull().sum()}\")\n",
    "\n",
    "# Display statistics\n",
    "print(\"\\nNumerical Features Statistics:\")\n",
    "print(df[numerical_cols].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features distribution by churn\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    # Box plot\n",
    "    df.boxplot(column=col, by='Churn', ax=axes[idx])\n",
    "    axes[idx].set_title(f'{col} by Churn', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Churn', fontsize=10)\n",
    "    axes[idx].set_ylabel(col, fontsize=10)\n",
    "\n",
    "plt.suptitle('Numerical Features Distribution by Churn', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    # Churn = No\n",
    "    df[df['Churn'] == 'No'][col].hist(ax=axes[0, idx], alpha=0.7, label='No Churn', color='#2ecc71')\n",
    "    # Churn = Yes\n",
    "    df[df['Churn'] == 'Yes'][col].hist(ax=axes[0, idx], alpha=0.7, label='Churn', color='#e74c3c')\n",
    "    axes[0, idx].set_title(f'{col} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, idx].set_xlabel(col, fontsize=10)\n",
    "    axes[0, idx].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[0, idx].legend()\n",
    "    \n",
    "    # Density plot\n",
    "    df[df['Churn'] == 'No'][col].plot(kind='density', ax=axes[1, idx], label='No Churn', color='#2ecc71')\n",
    "    df[df['Churn'] == 'Yes'][col].plot(kind='density', ax=axes[1, idx], label='Churn', color='#e74c3c')\n",
    "    axes[1, idx].set_title(f'{col} Density Plot', fontsize=12, fontweight='bold')\n",
    "    axes[1, idx].set_xlabel(col, fontsize=10)\n",
    "    axes[1, idx].set_ylabel('Density', fontsize=10)\n",
    "    axes[1, idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = df[numerical_cols].corr()\n",
    "\n",
    "# Visualize correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix - Numerical Features', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Data Preprocessing\n",
    "\n",
    "### 6.1 Handle Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values again\n",
    "print(\"Missing values before handling:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values in TotalCharges\n",
    "# Missing TotalCharges likely means new customers (tenure = 0)\n",
    "df['TotalCharges'].fillna(0, inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nAll missing values handled!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Handle Inconsistent Categorical Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'No internet service' and 'No phone service' with 'No'\n",
    "columns_to_fix = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                  'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n",
    "\n",
    "for col in columns_to_fix:\n",
    "    df[col] = df[col].replace(['No internet service', 'No phone service'], 'No')\n",
    "\n",
    "print(\"Categorical values standardized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "\n",
    "# Average charge per month (for customers with tenure > 0)\n",
    "df['AvgChargePerMonth'] = df.apply(\n",
    "    lambda x: x['TotalCharges'] / x['tenure'] if x['tenure'] > 0 else 0, axis=1\n",
    ")\n",
    "\n",
    "# Tenure groups\n",
    "def categorize_tenure(tenure):\n",
    "    if tenure <= 12:\n",
    "        return '0-12'\n",
    "    elif tenure <= 24:\n",
    "        return '13-24'\n",
    "    elif tenure <= 48:\n",
    "        return '25-48'\n",
    "    else:\n",
    "        return '49+'\n",
    "\n",
    "df['TenureGroup'] = df['tenure'].apply(categorize_tenure)\n",
    "\n",
    "# Count of services (excluding basic phone/internet)\n",
    "service_cols = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "df['ServiceCount'] = df[service_cols].apply(\n",
    "    lambda x: sum(x == 'Yes'), axis=1\n",
    ")\n",
    "\n",
    "print(\"Feature engineering completed!\")\n",
    "print(f\"\\nNew features created:\")\n",
    "print(\"- AvgChargePerMonth\")\n",
    "print(\"- TenureGroup\")\n",
    "print(\"- ServiceCount\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Encode Categorical Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for preprocessing\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Binary encoding for Yes/No columns\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling',\n",
    "               'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "               'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "\n",
    "for col in binary_cols:\n",
    "    df_processed[col] = df_processed[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Gender encoding\n",
    "df_processed['gender'] = df_processed['gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# MultipleLines encoding (already handled 'No phone service')\n",
    "df_processed['MultipleLines'] = df_processed['MultipleLines'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# One-hot encoding for multi-category columns\n",
    "multi_category_cols = ['InternetService', 'Contract', 'PaymentMethod', 'TenureGroup']\n",
    "\n",
    "df_processed = pd.get_dummies(df_processed, columns=multi_category_cols, prefix=multi_category_cols)\n",
    "\n",
    "print(\"Categorical encoding completed!\")\n",
    "print(f\"\\nNew shape: {df_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Prepare Features and Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_processed.drop(['customerID', 'Churn'], axis=1)\n",
    "y = df_processed['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Save Processed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for next notebook\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "X.to_csv('data/X_processed.csv', index=False)\n",
    "y.to_csv('data/y_processed.csv', index=False)\n",
    "\n",
    "print(\"Processed data saved successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- data/X_processed.csv\")\n",
    "print(\"- data/y_processed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "1. Dataset contains customer information with churn status\n",
    "2. Missing values in TotalCharges handled\n",
    "3. Categorical variables encoded appropriately\n",
    "4. New features created for better prediction\n",
    "5. Data ready for model training\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to Model Building notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
