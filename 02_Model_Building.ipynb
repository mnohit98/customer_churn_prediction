{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Customer Churn Prediction - Part 2: Model Building\n",
    "\n",
    "## Overview\n",
    "This notebook covers:\n",
    "1. Train-Test Split\n",
    "2. Feature Scaling\n",
    "3. Model Training (Multiple Algorithms)\n",
    "4. Hyperparameter Tuning\n",
    "5. Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
    "    XGBOOST_AVAILABLE = False\n",
    "\n",
    "# Save models\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load processed data from previous notebook\n",
    "X = pd.read_csv('data/X_processed.csv')\n",
    "y = pd.read_csv('data/y_processed.csv').squeeze()\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Maintain churn distribution\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set churn distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTesting set churn distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit scaler on training data only\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform test data using training scaler\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(\"Feature scaling completed!\")\n",
    "print(f\"\\nScaled training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Scaled testing set shape: {X_test_scaled.shape}\")\n",
    "\n",
    "# Save scaler for later use\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump(scaler, 'models/scaler.pkl')\n",
    "print(\"\\nScaler saved to models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Model Training - Baseline Models\n",
    "\n",
    "### 5.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize Logistic Regression\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr)\n",
    "lr_recall = recall_score(y_test, y_pred_lr)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr)\n",
    "lr_roc_auc = roc_auc_score(y_test, y_pred_proba_lr)\n",
    "\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(f\"Accuracy: {lr_accuracy:.4f}\")\n",
    "print(f\"Precision: {lr_precision:.4f}\")\n",
    "print(f\"Recall: {lr_recall:.4f}\")\n",
    "print(f\"F1-Score: {lr_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {lr_roc_auc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(lr_model, 'models/logistic_regression.pkl')\n",
    "print(\"\\nModel saved to models/logistic_regression.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.2 Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model (no scaling needed for tree-based models)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_proba_rf)\n",
    "\n",
    "print(\"Random Forest Results:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"Precision: {rf_precision:.4f}\")\n",
    "print(f\"Recall: {rf_recall:.4f}\")\n",
    "print(f\"F1-Score: {rf_f1:.4f}\")\n",
    "print(f\"ROC-AUC: {rf_roc_auc:.4f}\")\n",
    "\n",
    "# Save model\n",
    "joblib.dump(rf_model, 'models/random_forest.pkl')\n",
    "print(\"\\nModel saved to models/random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.3 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if XGBOOST_AVAILABLE:\n",
    "    # Initialize XGBoost\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    \n",
    "    # Train the model\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_xgb = xgb_model.predict(X_test)\n",
    "    y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    xgb_accuracy = accuracy_score(y_test, y_pred_xgb)\n",
    "    xgb_precision = precision_score(y_test, y_pred_xgb)\n",
    "    xgb_recall = recall_score(y_test, y_pred_xgb)\n",
    "    xgb_f1 = f1_score(y_test, y_pred_xgb)\n",
    "    xgb_roc_auc = roc_auc_score(y_test, y_pred_proba_xgb)\n",
    "    \n",
    "    print(\"XGBoost Results:\")\n",
    "    print(f\"Accuracy: {xgb_accuracy:.4f}\")\n",
    "    print(f\"Precision: {xgb_precision:.4f}\")\n",
    "    print(f\"Recall: {xgb_recall:.4f}\")\n",
    "    print(f\"F1-Score: {xgb_f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {xgb_roc_auc:.4f}\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(xgb_model, 'models/xgboost.pkl')\n",
    "    print(\"\\nModel saved to models/xgboost.pkl\")\n",
    "else:\n",
    "    print(\"XGBoost not available. Skipping...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5.4 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest'],\n",
    "    'Accuracy': [lr_accuracy, rf_accuracy],\n",
    "    'Precision': [lr_precision, rf_precision],\n",
    "    'Recall': [lr_recall, rf_recall],\n",
    "    'F1-Score': [lr_f1, rf_f1],\n",
    "    'ROC-AUC': [lr_roc_auc, rf_roc_auc]\n",
    "}\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    comparison_data['Model'].append('XGBoost')\n",
    "    comparison_data['Accuracy'].append(xgb_accuracy)\n",
    "    comparison_data['Precision'].append(xgb_precision)\n",
    "    comparison_data['Recall'].append(xgb_recall)\n",
    "    comparison_data['F1-Score'].append(xgb_f1)\n",
    "    comparison_data['ROC-AUC'].append(xgb_roc_auc)\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    comparison_df.plot(x='Model', y=metric, kind='bar', ax=axes[row, col], legend=False)\n",
    "    axes[row, col].set_title(f'{metric} Comparison', fontweight='bold')\n",
    "    axes[row, col].set_ylabel(metric)\n",
    "    axes[row, col].set_xticklabels(axes[row, col].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('models/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Hyperparameter Tuning\n",
    "\n",
    "### 6.1 Tune Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    param_grid=rf_param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Perform grid search (this may take some time)\n",
    "print(\"Starting Random Forest hyperparameter tuning...\")\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters\n",
    "print(f\"\\nBest parameters: {rf_grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation score: {rf_grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train best model\n",
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_rf_tuned = rf_best_model.predict(X_test)\n",
    "y_pred_proba_rf_tuned = rf_best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "rf_tuned_accuracy = accuracy_score(y_test, y_pred_rf_tuned)\n",
    "rf_tuned_roc_auc = roc_auc_score(y_test, y_pred_proba_rf_tuned)\n",
    "\n",
    "print(f\"\\nTuned Random Forest Test Accuracy: {rf_tuned_accuracy:.4f}\")\n",
    "print(f\"Tuned Random Forest Test ROC-AUC: {rf_tuned_roc_auc:.4f}\")\n",
    "\n",
    "# Save tuned model\n",
    "joblib.dump(rf_best_model, 'models/random_forest_tuned.pkl')\n",
    "print(\"\\nTuned model saved to models/random_forest_tuned.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.2 Tune XGBoost (if available)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "if XGBOOST_AVAILABLE:\n",
    "    # Define parameter grid for XGBoost\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 1.0]\n",
    "    }\n",
    "    \n",
    "    # Initialize GridSearchCV\n",
    "    xgb_grid_search = GridSearchCV(\n",
    "        estimator=xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        param_grid=xgb_param_grid,\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Perform grid search\n",
    "    print(\"Starting XGBoost hyperparameter tuning...\")\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best parameters\n",
    "    print(f\"\\nBest parameters: {xgb_grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {xgb_grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Train best model\n",
    "    xgb_best_model = xgb_grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    y_pred_xgb_tuned = xgb_best_model.predict(X_test)\n",
    "    y_pred_proba_xgb_tuned = xgb_best_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    xgb_tuned_accuracy = accuracy_score(y_test, y_pred_xgb_tuned)\n",
    "    xgb_tuned_roc_auc = roc_auc_score(y_test, y_pred_proba_xgb_tuned)\n",
    "    \n",
    "    print(f\"\\nTuned XGBoost Test Accuracy: {xgb_tuned_accuracy:.4f}\")\n",
    "    print(f\"Tuned XGBoost Test ROC-AUC: {xgb_tuned_roc_auc:.4f}\")\n",
    "    \n",
    "    # Save tuned model\n",
    "    joblib.dump(xgb_best_model, 'models/xgboost_tuned.pkl')\n",
    "    print(\"\\nTuned model saved to models/xgboost_tuned.pkl\")\n",
    "else:\n",
    "    print(\"XGBoost not available. Skipping tuning...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 7: Save Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Save train-test split data for evaluation notebook\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "X_test.to_csv('data/X_test.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)\n",
    "\n",
    "print(\"Training and test data saved successfully!\")\n",
    "print(\"Files saved:\")\n",
    "print(\"- data/X_train.csv\")\n",
    "print(\"- data/X_test.csv\")\n",
    "print(\"- data/y_train.csv\")\n",
    "print(\"- data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "### Models Trained:\n",
    "1. Logistic Regression (baseline)\n",
    "2. Random Forest (with hyperparameter tuning)\n",
    "3. XGBoost (with hyperparameter tuning, if available)\n",
    "\n",
    "### Next Steps:\n",
    "- Proceed to Model Evaluation notebook for detailed performance analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}