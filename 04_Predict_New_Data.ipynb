{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction - Part 4: Predict New Data\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates how to use the trained model to predict churn for new customer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Trained Model and Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model (Random Forest)\n",
    "model = joblib.load('models/random_forest.pkl')\n",
    "scaler = joblib.load('models/scaler.pkl')\n",
    "\n",
    "# Load processed feature names from training data to ensure consistency\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "print(\"Model and scaler loaded successfully!\")\n",
    "print(f\"\\nModel type: Random Forest\")\n",
    "print(f\"Number of features: {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_new_data(new_customer_data, feature_names):\n",
    "    \"\"\"\n",
    "    Preprocess new customer data to match training data format\n",
    "    \"\"\"\n",
    "    if isinstance(new_customer_data, dict):\n",
    "        df = pd.DataFrame([new_customer_data])\n",
    "    else:\n",
    "        df = new_customer_data.copy()\n",
    "    \n",
    "    # 1. Handle Missing Values\n",
    "    if 'TotalCharges' in df.columns:\n",
    "        df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "        df['TotalCharges'].fillna(0, inplace=True)\n",
    "    \n",
    "    # 2. Standardize Categorical Values\n",
    "    columns_to_fix = ['OnlineSecurity', 'OnlineBackup', 'DeviceProtection', \n",
    "                      'TechSupport', 'StreamingTV', 'StreamingMovies', 'MultipleLines']\n",
    "    for col in columns_to_fix:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].replace(['No internet service', 'No phone service'], 'No')\n",
    "    \n",
    "    # 3. Feature Engineering\n",
    "    if 'tenure' in df.columns and 'TotalCharges' in df.columns:\n",
    "        df['AvgChargePerMonth'] = df.apply(\n",
    "            lambda x: x['TotalCharges'] / x['tenure'] if x['tenure'] > 0 else 0, axis=1\n",
    "        )\n",
    "    \n",
    "    # 4. Encoding\n",
    "    binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling',\n",
    "                   'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                   'TechSupport', 'StreamingTV', 'StreamingMovies']\n",
    "    for col in binary_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    if 'gender' in df.columns: df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})\n",
    "    if 'MultipleLines' in df.columns: df['MultipleLines'] = df['MultipleLines'].map({'Yes': 1, 'No': 0})\n",
    "    \n",
    "    # 5. One-Hot Encoding and Alignment\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    # Ensure all training features are present (add 0s for missing dummies)\n",
    "    for col in feature_names:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0\n",
    "    \n",
    "    return df[feature_names]\n",
    "\n",
    "print(\"Preprocessing function created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_churn(new_data, model, feature_names):\n",
    "    processed = preprocess_new_data(new_data, feature_names)\n",
    "    pred = model.predict(processed)\n",
    "    proba = model.predict_proba(processed)[:, 1]\n",
    "    return pred, proba\n",
    "\n",
    "print(\"Prediction function created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_customer = {\n",
    "    'gender': 'Male',\n",
    "    'SeniorCitizen': 0,\n",
    "    'Partner': 'No',\n",
    "    'Dependents': 'No',\n",
    "    'tenure': 2,\n",
    "    'PhoneService': 'Yes',\n",
    "    'MultipleLines': 'No',\n",
    "    'InternetService': 'Fiber optic',\n",
    "    'OnlineSecurity': 'No',\n",
    "    'OnlineBackup': 'No',\n",
    "    'DeviceProtection': 'No',\n",
    "    'TechSupport': 'No',\n",
    "    'StreamingTV': 'Yes',\n",
    "    'StreamingMovies': 'Yes',\n",
    "    'Contract': 'Month-to-month',\n",
    "    'PaperlessBilling': 'Yes',\n",
    "    'PaymentMethod': 'Electronic check',\n",
    "    'MonthlyCharges': 100.0,\n",
    "    'TotalCharges': 200.0\n",
    "}\n",
    "\n",
    "pred, prob = predict_churn(example_customer, model, feature_names)\n",
    "print(f\"Prediction: {'Churn' if pred[0] == 1 else 'Stay'}\")\n",
    "print(f\"Probability: {prob[0]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This pipeline allows for real-time predictions. \n",
    "\n",
    "\n",
    "\n",
    "### Next Steps:\n",
    "- Wrap this code into a **FastAPI** or **Flask** endpoint.\n",
    "- Monitor model performance over time to detect **Data Drift**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
